{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## La neurona se activa si al menos una de sus entradas es verdadera (1) y no se activa (0) solo si todas sus entradas son falsas"
      ],
      "metadata": {
        "id": "98CruCa6nV1D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRZayvypiAO6",
        "outputId": "7abfe315-3d17-45d8-f761-4abd46acd09d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos finales: [0.64973174 0.18400357]\n",
            "Sesgo final: [-0.00689993]\n",
            "\n",
            "Probando el perceptrón:\n",
            "Entrada: [0 0], Salida esperada: 0, Salida predicha: 0\n",
            "Entrada: [0 1], Salida esperada: 1, Salida predicha: 1\n",
            "Entrada: [1 0], Salida esperada: 1, Salida predicha: 1\n",
            "Entrada: [1 1], Salida esperada: 1, Salida predicha: 1\n"
          ]
        }
      ],
      "source": [
        "  #Importamos la libreria numpy\n",
        "import numpy as np\n",
        "\n",
        "# Definición de la función de activación (escalón unitario)\n",
        "# Esta función devuelve 1 si la entrada es mayor o igual a 0, y 0 en caso contrario.\n",
        "def activacion(suma_ponderada):\n",
        "    return 1 if suma_ponderada >= 0 else 0\n",
        "\n",
        "# Datos de entrenamiento para la función OR\n",
        "# Cada fila representa un ejemplo: [entrada1, entrada2, salida_esperada]\n",
        "# (0, 0) -> 0\n",
        "# (0, 1) -> 1\n",
        "# (1, 0) -> 1\n",
        "# (1, 1) -> 1\n",
        "datos_entrenamiento = np.array([\n",
        "    [0, 0, 0],\n",
        "    [0, 1, 1],\n",
        "    [1, 0, 1],\n",
        "    [1, 1, 1]\n",
        "])\n",
        "\n",
        "# Inicialización de los pesos y el sesgo\n",
        "# Se inicializan con valores pequeños aleatorios\n",
        "pesos = np.random.rand(2) # Dos pesos, uno para cada entrada\n",
        "sesgo = np.random.rand(1) # Un sesgo\n",
        "\n",
        "# Tasa de aprendizaje\n",
        "# Determina qué tan rápido se ajustan los pesos y el sesgo durante el entrenamiento\n",
        "tasa_aprendizaje = 0.1\n",
        "\n",
        "# Número de épocas (iteraciones de entrenamiento)\n",
        "# Cuántas veces se recorrerán todos los datos de entrenamiento\n",
        "epocas = 100\n",
        "\n",
        "# Entrenamiento del perceptrón\n",
        "for epoca in range(epocas):\n",
        "    # Iterar sobre cada ejemplo en los datos de entrenamiento\n",
        "    for ejemplo in datos_entrenamiento:\n",
        "        entrada = ejemplo[:2] # Las dos primeras columnas son las entradas\n",
        "        salida_esperada = ejemplo[2] # La última columna es la salida esperada\n",
        "\n",
        "        # Calcular la suma ponderada de las entradas y los pesos, más el sesgo\n",
        "        # (entrada1 * peso1) + (entrada2 * peso2) + sesgo\n",
        "        suma_ponderada = np.dot(entrada, pesos) + sesgo\n",
        "\n",
        "        # Aplicar la función de activación para obtener la salida predicha por el perceptrón\n",
        "        salida_predicha = activacion(suma_ponderada)\n",
        "\n",
        "        # Calcular el error\n",
        "        # La diferencia entre la salida esperada y la salida predicha\n",
        "        error = salida_esperada - salida_predicha\n",
        "\n",
        "        # Actualizar los pesos y el sesgo si hay un error\n",
        "        # Se ajustan en proporción al error, la tasa de aprendizaje y la entrada\n",
        "        pesos += tasa_aprendizaje * error * entrada\n",
        "        sesgo += tasa_aprendizaje * error\n",
        "\n",
        "print(f\"Pesos finales: {pesos}\")\n",
        "print(f\"Sesgo final: {sesgo}\")\n",
        "\n",
        "# Prueba del perceptrón entrenado\n",
        "print(\"\\nProbando el perceptrón:\")\n",
        "for ejemplo in datos_entrenamiento:\n",
        "    entrada = ejemplo[:2]\n",
        "    salida_esperada = ejemplo[2]\n",
        "\n",
        "    # Calcular la suma ponderada con los pesos y sesgo entrenados\n",
        "    suma_ponderada = np.dot(entrada, pesos) + sesgo\n",
        "\n",
        "    # Obtener la salida predicha\n",
        "    salida_predicha = activacion(suma_ponderada)\n",
        "\n",
        "    # Imprimir la entrada, la salida esperada y la salida predicha\n",
        "    print(f\"Entrada: {entrada}, Salida esperada: {salida_esperada}, Salida predicha: {salida_predicha}\")"
      ]
    }
  ]
}